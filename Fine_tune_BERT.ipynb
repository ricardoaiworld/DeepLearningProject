{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine-tune BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "iaXUb-2YZwlC",
        "sOo9xoViaPj9",
        "U8q6P9v05zsF",
        "O2_lf3VOxWG1",
        "9R1TUhj66UOr",
        "mja53ZFO7AK6",
        "M5cF0iOE_rir"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyKKjt7JSg8J"
      },
      "source": [
        "**CS-GY 9223: Deep Learning Final Project: Solving Natural Language Processing with Disaster Tweets on Kaggle with BERT**\r\n",
        "\r\n",
        "by:\r\n",
        "\r\n",
        "Yan Sun    <ys3928@nyu.edu>\r\n",
        "\r\n",
        "Zhenming Wang <zw2365@nyu.edu>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPRcd6EmZTuA"
      },
      "source": [
        "**Section 2: Fine-tune BERT**\r\n",
        "\r\n",
        "Reference:https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaXUb-2YZwlC"
      },
      "source": [
        "# Step 0: Set Up Working Environment And Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOOxVc-ZZo-u",
        "outputId": "5122bb49-84ff-4d64-a808-d4b29256b2a3"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELJTnyuyZt3c",
        "outputId": "9c6705a7-506f-4778-82c1-6d48e0f2490c"
      },
      "source": [
        "import os\r\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Deep Learning Final Project\"   \r\n",
        "                                       \r\n",
        "%cd /content/gdrive/My Drive/Deep Learning Final Project\r\n",
        "\r\n",
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Deep Learning Final Project\n",
            "/content/gdrive/My Drive/Deep Learning Final Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-baO6CG0s2nk",
        "outputId": "8002ca8b-1915-4054-d189-a9161136d028"
      },
      "source": [
        "!pip install -qq transformers\r\n",
        "\r\n",
        "import transformers\r\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\r\n",
        "import torch\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "from pylab import rcParams\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from scipy.stats import spearmanr\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import confusion_matrix, classification_report\r\n",
        "from collections import defaultdict\r\n",
        "from textwrap import wrap\r\n",
        "\r\n",
        "from torch import nn, optim\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "RANDOM_SEED = 42\r\n",
        "np.random.seed(RANDOM_SEED)\r\n",
        "torch.manual_seed(RANDOM_SEED)\r\n",
        "\r\n",
        "# Detect GPU\r\n",
        "if torch.cuda.is_available():   \r\n",
        "   device = torch.device(\"cuda\")\r\n",
        "   print('Using GPU ', torch.cuda.get_device_name(0))\r\n",
        "else:\r\n",
        "   device = torch.device(\"cpu\")\r\n",
        "   print('Using CPU')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.4MB 7.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 24.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 61.2MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Using GPU  Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gdw_0tgZ9S6"
      },
      "source": [
        "# Step 1: BERT Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOo9xoViaPj9"
      },
      "source": [
        "## 1.1 Read input data into dataframse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLTUPGHavM2p"
      },
      "source": [
        "# Read in the data cleaned data files \r\n",
        "train = pd.read_csv('train_cleaned.csv')\r\n",
        "test = pd.read_csv('test_cleaned.csv')\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "OxcdbDivwze-",
        "outputId": "1c6c3d61-3dbf-4659-bbc3-97347c79d0ae"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to shelter in place are be...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13000 people receive wildfires evacuation orde...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  id  ...                                               text target\n",
              "0           0   1  ...  Our Deeds are the Reason of this earthquake Ma...      1\n",
              "1           1   4  ...              Forest fire near La Ronge Sask Canada      1\n",
              "2           2   5  ...  All residents asked to shelter in place are be...      1\n",
              "3           3   6  ...  13000 people receive wildfires evacuation orde...      1\n",
              "4           4   7  ...  Just got sent this photo from Ruby Alaska as s...      1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8q6P9v05zsF"
      },
      "source": [
        "## 1.2 Helper function for tokenization and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9-0nVGlvsmg"
      },
      "source": [
        "# Helper function to tokenize a dataset using BERT tokenizer\r\n",
        "class DisasterTweetDataset(Dataset):\r\n",
        "  def __init__(self, text, targets, tokenizer, max_len):\r\n",
        "    self.text = text\r\n",
        "    self.targets = targets\r\n",
        "    self.tokenizer = tokenizer\r\n",
        "    self.max_len = max_len\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.text)\r\n",
        "  def __getitem__(self, item):\r\n",
        "    text = str(self.text[item])\r\n",
        "    target = self.targets[item]\r\n",
        "    encoding = self.tokenizer.encode_plus(\r\n",
        "      text,\r\n",
        "      add_special_tokens=True,\r\n",
        "      max_length=self.max_len,\r\n",
        "      truncation=True,\r\n",
        "      return_token_type_ids=False,\r\n",
        "      padding='max_length',\r\n",
        "      return_attention_mask=True,\r\n",
        "      return_tensors='pt',\r\n",
        "    )\r\n",
        "    return {\r\n",
        "      'text': text,\r\n",
        "      'input_ids': encoding['input_ids'].flatten(),\r\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\r\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\r\n",
        "    }"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtN3MD-fwhGM"
      },
      "source": [
        "# Helper function to create dataloaders\r\n",
        "def create_data_loader(df, tokenizer, max_len, batch_size):\r\n",
        "  ds = DisasterTweetDataset(\r\n",
        "    text=df.text.to_numpy(),\r\n",
        "    targets=df.target.to_numpy(),\r\n",
        "    tokenizer=tokenizer,\r\n",
        "    max_len=max_len\r\n",
        "  )\r\n",
        "  return DataLoader(\r\n",
        "    ds,\r\n",
        "    batch_size=batch_size,\r\n",
        "    num_workers=4\r\n",
        "  )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2_lf3VOxWG1"
      },
      "source": [
        "## 1.3 The BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlohvPZMxct-"
      },
      "source": [
        "class FinetuneBertClassifier(nn.Module):\r\n",
        "  def __init__(self, n_classes):\r\n",
        "    super(FinetuneBertClassifier, self).__init__()\r\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\r\n",
        "    self.drop = nn.Dropout(p=0.3)\r\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\r\n",
        "  def forward(self, input_ids, attention_mask):\r\n",
        "    outputs = self.bert(\r\n",
        "      input_ids=input_ids,\r\n",
        "      attention_mask=attention_mask\r\n",
        "    )\r\n",
        "    output = self.drop(outputs[1])\r\n",
        "    return self.out(output)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R1TUhj66UOr"
      },
      "source": [
        "## 1.4 Training and Evaluating Epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wWDC0nayfAZ"
      },
      "source": [
        "# This method defines the operations in one trainning epoch\r\n",
        "def train_epoch(\r\n",
        "  model,\r\n",
        "  data_loader,\r\n",
        "  loss_fn,\r\n",
        "  optimizer,\r\n",
        "  device,\r\n",
        "  scheduler,\r\n",
        "  n_examples\r\n",
        "):\r\n",
        "  model = model.train()\r\n",
        "  losses = []\r\n",
        "  correct_predictions = 0\r\n",
        "\r\n",
        "\r\n",
        "  for d in data_loader:\r\n",
        "    input_ids = d[\"input_ids\"].to(device)\r\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\r\n",
        "    targets = d[\"targets\"].to(device)\r\n",
        "    outputs = model(\r\n",
        "      input_ids=input_ids,\r\n",
        "      attention_mask=attention_mask\r\n",
        "    )\r\n",
        "    _, preds = torch.max(outputs, dim=1)\r\n",
        "    loss = loss_fn(outputs, targets)\r\n",
        "    correct_predictions += torch.sum(preds == targets)\r\n",
        "    losses.append(loss.item())\r\n",
        "    loss.backward()\r\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\r\n",
        "    optimizer.step()\r\n",
        "    scheduler.step()\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "      \r\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrVJpnSOyuEn"
      },
      "source": [
        "# This method defines the operations in one evaluating epoch\r\n",
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\r\n",
        "  model = model.eval()\r\n",
        "  losses = []\r\n",
        "  correct_predictions = 0\r\n",
        "  with torch.no_grad():\r\n",
        "    for d in data_loader:\r\n",
        "      input_ids = d[\"input_ids\"].to(device)\r\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\r\n",
        "      targets = d[\"targets\"].to(device)\r\n",
        "      outputs = model(\r\n",
        "        input_ids=input_ids,\r\n",
        "        attention_mask=attention_mask\r\n",
        "      )\r\n",
        "      _, preds = torch.max(outputs, dim=1)\r\n",
        "      loss = loss_fn(outputs, targets)\r\n",
        "      correct_predictions += torch.sum(preds == targets)\r\n",
        "      losses.append(loss.item())\r\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDMOtHpV67qc"
      },
      "source": [
        "# Step 2: Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mja53ZFO7AK6"
      },
      "source": [
        "## 2.1 Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g152CI19FQ6"
      },
      "source": [
        "For this project, we will be tuning with learning rate. For a given choice of learning rate, we apply 5-fold cross validation on the training set and train for 5 epochs\r\n",
        " within each fold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSLumj4u5DKT"
      },
      "source": [
        "# Hyperparam tuning \r\n",
        "lr_list = [1e-5, 2e-5, 5e-5]\r\n",
        "\r\n",
        "# Define some constants\r\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\r\n",
        "EPOCHS = 5\r\n",
        "BATCH_SIZE = 32\r\n",
        "DROPOUT = 0.3\r\n",
        "MAX_LEN = 32\r\n",
        "TOKENIZER = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\r\n",
        "\r\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWQN_16sccae"
      },
      "source": [
        "from sklearn.model_selection import KFold\r\n",
        "# Cross Validation\r\n",
        "kf = KFold(n_splits=5, shuffle=True)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lrc65YVkcgdB",
        "outputId": "6ddeb346-8d04-4cc5-a1e6-6c0a064e959d"
      },
      "source": [
        "\r\n",
        "# For each learning rate\r\n",
        "lr_history_list = []\r\n",
        "for lr in lr_list:\r\n",
        "  print('Learning rate: ', lr)\r\n",
        "  print('-' * 10)\r\n",
        "\r\n",
        "  # Create model instance\r\n",
        "  model = FinetuneBertClassifier(2)\r\n",
        "  model = model.to(device)\r\n",
        "  \r\n",
        "  # Define optimizer, loss fucntion and scheduler\r\n",
        "  optimizer = AdamW(model.parameters(), lr=lr, correct_bias=False)\r\n",
        "  total_steps = len(train_data_loader) * EPOCHS\r\n",
        "  scheduler = get_linear_schedule_with_warmup(\r\n",
        "    optimizer,\r\n",
        "    num_warmup_steps=0,\r\n",
        "    num_training_steps=total_steps\r\n",
        "  )\r\n",
        "  loss_fn = nn.CrossEntropyLoss().to(device)\r\n",
        "\r\n",
        "\r\n",
        "  fold_history_list = []\r\n",
        "  fold_count = 1\r\n",
        "  # For each choice of lr, perform 5-fold cross validation\r\n",
        "  for train_index, val_index in kf.split(train):\r\n",
        "    # Within each fold\r\n",
        "    print('Fold: ', fold_count)\r\n",
        "    print('-' * 10)\r\n",
        "    fold_count += 1\r\n",
        "\r\n",
        "    # Split the training data into train and validation set\r\n",
        "    train_data = train.iloc[train_index] \r\n",
        "    val_data = train.iloc[val_index] \r\n",
        "\r\n",
        "    # Count the number of training and validation set\r\n",
        "    num_train_data = len(train_data)\r\n",
        "    num_val_data = len(val_data)\r\n",
        "\r\n",
        "    # Create dataloaders for training and validation set\r\n",
        "    train_data_loader = create_data_loader(train_data, TOKENIZER, MAX_LEN, BATCH_SIZE)\r\n",
        "    val_data_loader = create_data_loader(val_data, TOKENIZER, MAX_LEN, BATCH_SIZE)\r\n",
        "\r\n",
        "\r\n",
        "    # Train the model for some number of epochs\r\n",
        "    history = defaultdict(list)\r\n",
        "\r\n",
        "    for epoch in range(EPOCHS):\r\n",
        "      print(f'Epoch {epoch + 1}/{EPOCHS}')\r\n",
        "      print('-' * 10)\r\n",
        "\r\n",
        "      # Train\r\n",
        "      train_acc, train_loss = train_epoch(\r\n",
        "        model,\r\n",
        "        train_data_loader,\r\n",
        "        loss_fn,\r\n",
        "        optimizer,\r\n",
        "        device,\r\n",
        "        scheduler,\r\n",
        "        len(train_data)\r\n",
        "      )\r\n",
        "      print(f'Train loss {train_loss} accuracy {train_acc}')\r\n",
        "\r\n",
        "      # Validate\r\n",
        "      val_acc, val_loss = eval_model(\r\n",
        "        model,\r\n",
        "        val_data_loader,\r\n",
        "        loss_fn,\r\n",
        "        device,\r\n",
        "        len(val_data)\r\n",
        "      )\r\n",
        "      print(f'Val   loss {val_loss} accuracy {val_acc}')\r\n",
        "    \r\n",
        "      history['train_acc'].append(train_acc)\r\n",
        "      history['train_loss'].append(train_loss)\r\n",
        "      history['val_acc'].append(val_acc)\r\n",
        "      history['val_loss'].append(val_loss)\r\n",
        "\r\n",
        "    # When we finish all epochs of current fold, \r\n",
        "    # history will be of size (4, EPOCHS)\r\n",
        "\r\n",
        "\r\n",
        "    # Then we append all epoch histories in current fold\r\n",
        "    # into fold_history_list\r\n",
        "    fold_history_list.append(history)\r\n",
        "  \r\n",
        "  # When we are done with all 5 folds given a spefic value of lr,\r\n",
        "  # we append current fold history into lr_history_list\r\n",
        "  lr_history_list.append(fold_history_list)\r\n",
        "    \r\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  1e-05\n",
            "----------\n",
            "Fold:  1\n",
            "----------\n",
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.5130284367646066 accuracy 0.755336617405583\n",
            "Val   loss 0.4053769189243515 accuracy 0.8227183191070255\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.34924935056530526 accuracy 0.8617405582922825\n",
            "Val   loss 0.4266646867617965 accuracy 0.8279711096520026\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.2650770402308651 accuracy 0.9\n",
            "Val   loss 0.4578178980542968 accuracy 0.8378200919238344\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.21231217803043453 accuracy 0.9236453201970444\n",
            "Val   loss 0.5262484549311921 accuracy 0.8279711096520026\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.18044005631205884 accuracy 0.939408866995074\n",
            "Val   loss 0.5222695166788375 accuracy 0.8266579120157583\n",
            "Fold:  2\n",
            "----------\n",
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.2507795612339945 accuracy 0.9137931034482759\n",
            "Val   loss 0.15359202568652108 accuracy 0.9520682862770846\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.25375698569245364 accuracy 0.9129720853858785\n",
            "Val   loss 0.15359202568652108 accuracy 0.9520682862770846\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.2520228692199986 accuracy 0.9118226600985222\n",
            "Val   loss 0.15359202568652108 accuracy 0.9520682862770846\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.24786346156335393 accuracy 0.9121510673234812\n",
            "Val   loss 0.15359202568652108 accuracy 0.9520682862770846\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.2567492142704886 accuracy 0.9113300492610837\n",
            "Val   loss 0.15359202568652108 accuracy 0.9520682862770846\n",
            "Fold:  3\n",
            "----------\n",
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.2540946364151655 accuracy 0.9136288998357964\n",
            "Val   loss 0.14599168356896067 accuracy 0.9527248850952067\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.24975767880873218 accuracy 0.9124794745484401\n",
            "Val   loss 0.14599168356896067 accuracy 0.9527248850952067\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.2530389899322129 accuracy 0.913136288998358\n",
            "Val   loss 0.14599168356896067 accuracy 0.9527248850952067\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.2519258521923903 accuracy 0.9129720853858785\n",
            "Val   loss 0.14599168356896067 accuracy 0.9527248850952067\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.25013097613825613 accuracy 0.9144499178981937\n",
            "Val   loss 0.14599168356896067 accuracy 0.9527248850952067\n",
            "Fold:  4\n",
            "----------\n",
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.2593717943872106 accuracy 0.911672960105073\n",
            "Val   loss 0.14804322099856412 accuracy 0.9487516425755584\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.25562709170949516 accuracy 0.911672960105073\n",
            "Val   loss 0.14804322099856412 accuracy 0.9487516425755584\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.2511591541645463 accuracy 0.9147923165325891\n",
            "Val   loss 0.14804322099856412 accuracy 0.9487516425755584\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.25346706877706365 accuracy 0.9141356099162699\n",
            "Val   loss 0.14804322099856412 accuracy 0.9487516425755584\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.2545235136838347 accuracy 0.9141356099162699\n",
            "Val   loss 0.14804322099856412 accuracy 0.9487516425755584\n",
            "Fold:  5\n",
            "----------\n",
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.25958100151689967 accuracy 0.9129863733377114\n",
            "Val   loss 0.1286983306199545 accuracy 0.9559789750328516\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.2605472692807756 accuracy 0.9106879001805943\n",
            "Val   loss 0.1286983306199545 accuracy 0.9559789750328516\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.2532228345066036 accuracy 0.9142997865703497\n",
            "Val   loss 0.1286983306199545 accuracy 0.9559789750328516\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.2584538074388261 accuracy 0.910195370218355\n",
            "Val   loss 0.1286983306199545 accuracy 0.9559789750328516\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.2659034570715639 accuracy 0.9098670169101953\n",
            "Val   loss 0.1286983306199545 accuracy 0.9559789750328516\n",
            "Learning rate:  2e-05\n",
            "----------\n",
            "Fold:  1\n",
            "----------\n",
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.5290650328650525 accuracy 0.7609195402298851\n",
            "Val   loss 0.39005325579394895 accuracy 0.8273145108338804\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.35984412145298655 accuracy 0.8573070607553367\n",
            "Val   loss 0.4503088945833345 accuracy 0.8049901510177281\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.24888874145946344 accuracy 0.906568144499179\n",
            "Val   loss 0.5220921556465328 accuracy 0.8102429415627052\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.17443689724786393 accuracy 0.9367816091954023\n",
            "Val   loss 0.5973940906502927 accuracy 0.8214051214707813\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.11821457799353408 accuracy 0.958456486042693\n",
            "Val   loss 0.6228816600050777 accuracy 0.8214051214707813\n",
            "Fold:  2\n",
            "----------\n",
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.22540072899882277 accuracy 0.9274220032840723\n",
            "Val   loss 0.08793237753464685 accuracy 0.9678266579120157\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.22855541031656504 accuracy 0.9279146141215107\n",
            "Val   loss 0.08793237753464685 accuracy 0.9678266579120157\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.227544732499107 accuracy 0.9282430213464696\n",
            "Val   loss 0.08793237753464685 accuracy 0.9678266579120157\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.23529999290290654 accuracy 0.9269293924466339\n",
            "Val   loss 0.08793237753464685 accuracy 0.9678266579120157\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.2344598545392985 accuracy 0.9246305418719212\n",
            "Val   loss 0.08793237753464685 accuracy 0.9678266579120157\n",
            "Fold:  3\n",
            "----------\n",
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.23277889910953714 accuracy 0.9302134646962233\n",
            "Val   loss 0.09798949135680839 accuracy 0.9652002626395272\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.224185396519158 accuracy 0.9302134646962233\n",
            "Val   loss 0.09798949135680839 accuracy 0.9652002626395272\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.22359508923035484 accuracy 0.9321839080459771\n",
            "Val   loss 0.09798949135680839 accuracy 0.9652002626395272\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.22477709748587177 accuracy 0.9295566502463054\n",
            "Val   loss 0.09798949135680839 accuracy 0.9652002626395272\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.23040479472996814 accuracy 0.9269293924466339\n",
            "Val   loss 0.09798949135680839 accuracy 0.9652002626395272\n",
            "Fold:  4\n",
            "----------\n",
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.23463913733054304 accuracy 0.9262846823181743\n",
            "Val   loss 0.08065397294800884 accuracy 0.9691195795006571\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.23574374867932316 accuracy 0.9256279757018552\n",
            "Val   loss 0.08065397294800884 accuracy 0.9691195795006571\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.23797975229806417 accuracy 0.9261205056640945\n",
            "Val   loss 0.08065397294800884 accuracy 0.9691195795006571\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.23392708119948477 accuracy 0.9282548021671319\n",
            "Val   loss 0.08065397294800884 accuracy 0.9691195795006571\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.23486546680687181 accuracy 0.9277622722048925\n",
            "Val   loss 0.08065397294800884 accuracy 0.9691195795006571\n",
            "Fold:  5\n",
            "----------\n",
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.24023188864909775 accuracy 0.9248070924314562\n",
            "Val   loss 0.05842420992606397 accuracy 0.9763469119579501\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.24326364355434843 accuracy 0.9241503858151371\n",
            "Val   loss 0.05842420992606397 accuracy 0.9763469119579501\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.2394324801435587 accuracy 0.9241503858151371\n",
            "Val   loss 0.05842420992606397 accuracy 0.9763469119579501\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.2397043058875441 accuracy 0.9267772122804137\n",
            "Val   loss 0.05842420992606397 accuracy 0.9763469119579501\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.233259010000681 accuracy 0.9254637990477754\n",
            "Val   loss 0.05842420992606397 accuracy 0.9763469119579501\n",
            "Learning rate:  5e-05\n",
            "----------\n",
            "Fold:  1\n",
            "----------\n",
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.7446132643996733 accuracy 0.5146141215106732\n",
            "Val   loss 0.6753781127432982 accuracy 0.6211424819435325\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.7303430261724282 accuracy 0.5208538587848933\n",
            "Val   loss 0.6693197054167589 accuracy 0.6211424819435325\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.7244691638110196 accuracy 0.5333333333333333\n",
            "Val   loss 0.6754957723120848 accuracy 0.6211424819435325\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.7183134377938915 accuracy 0.5280788177339901\n",
            "Val   loss 0.6700711436569691 accuracy 0.6211424819435325\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.7154919258587024 accuracy 0.5241379310344828\n",
            "Val   loss 0.6692064888775349 accuracy 0.6211424819435325\n",
            "Fold:  2\n",
            "----------\n",
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.7101444383566292 accuracy 0.5229885057471264\n",
            "Val   loss 0.6792360780139765 accuracy 0.5869993434011819\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.7062396513229889 accuracy 0.5318555008210181\n",
            "Val   loss 0.6792360780139765 accuracy 0.5869993434011819\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.7020352957136344 accuracy 0.5403940886699508\n",
            "Val   loss 0.6792360780139765 accuracy 0.5869993434011819\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.7027493175411723 accuracy 0.5385878489326765\n",
            "Val   loss 0.6792360780139765 accuracy 0.5869993434011819\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.7040200589214944 accuracy 0.538752052545156\n",
            "Val   loss 0.6792360780139765 accuracy 0.5869993434011819\n",
            "Fold:  3\n",
            "----------\n",
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.699890116746513 accuracy 0.542528735632184\n",
            "Val   loss 0.6982433795928955 accuracy 0.5200262639527249\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.7012917402527095 accuracy 0.5433497536945813\n",
            "Val   loss 0.6982433795928955 accuracy 0.5200262639527249\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.6985117387397127 accuracy 0.5420361247947455\n",
            "Val   loss 0.6982433795928955 accuracy 0.5200262639527249\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.6979243533773573 accuracy 0.545648604269294\n",
            "Val   loss 0.6982433795928955 accuracy 0.5200262639527249\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.6986631579424074 accuracy 0.5417077175697865\n",
            "Val   loss 0.6982433795928955 accuracy 0.5200262639527249\n",
            "Fold:  4\n",
            "----------\n",
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.7081351782638989 accuracy 0.5289771794450829\n",
            "Val   loss 0.6778418657680353 accuracy 0.5893561103810775\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.706357379234274 accuracy 0.5314398292562797\n",
            "Val   loss 0.6778418657680353 accuracy 0.5893561103810775\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.7083574517859215 accuracy 0.5320965358725989\n",
            "Val   loss 0.6778418657680353 accuracy 0.5893561103810775\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.7001782509044827 accuracy 0.5404695452306681\n",
            "Val   loss 0.6778418657680353 accuracy 0.5893561103810775\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.7006151242405957 accuracy 0.5450664915449023\n",
            "Val   loss 0.6778418657680353 accuracy 0.5893561103810775\n",
            "Fold:  5\n",
            "----------\n",
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.7001465190767617 accuracy 0.5388277786898703\n",
            "Val   loss 0.6953762123982111 accuracy 0.5341655716162944\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.6997712463608587 accuracy 0.5434247250041044\n",
            "Val   loss 0.6953762123982111 accuracy 0.5341655716162944\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.6997994490318897 accuracy 0.5347233623378755\n",
            "Val   loss 0.6953762123982111 accuracy 0.5341655716162944\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.6994096440170448 accuracy 0.5429321950418651\n",
            "Val   loss 0.6953762123982111 accuracy 0.5341655716162944\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.6990966060398761 accuracy 0.5414546051551469\n",
            "Val   loss 0.6953762123982111 accuracy 0.5341655716162944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qjJRn4pik3N",
        "outputId": "e5438ada-c2ea-4954-c20e-32748c51ab18"
      },
      "source": [
        "len(lr_history_list) # 3 because we are tuning with 3 different values of lr's"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OspSw5C7oWzP",
        "outputId": "b9213129-2ee6-4502-947f-14a0c76f5a38"
      },
      "source": [
        "len(lr_history_list[0]) # 5 because we do 5-fold cross validation for each choice of lr"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OGWoQ_-obnL",
        "outputId": "ee905628-05e2-4b34-fef0-12ed51c77249"
      },
      "source": [
        "lr_history_list[0][0]['train_acc'] # a list of 5 tensors because we train for 5 epochs within each fold"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(0.7553, device='cuda:0', dtype=torch.float64),\n",
              " tensor(0.8617, device='cuda:0', dtype=torch.float64),\n",
              " tensor(0.9000, device='cuda:0', dtype=torch.float64),\n",
              " tensor(0.9236, device='cuda:0', dtype=torch.float64),\n",
              " tensor(0.9394, device='cuda:0', dtype=torch.float64)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEaFjuqUofXP"
      },
      "source": [
        "# Make a plot of the validation loss during training\r\n",
        "lr_val_loss = []\r\n",
        "for folds in lr_history_list:\r\n",
        "  # Compute average validation loss of each fold with current lr\r\n",
        "  folds_val_loss = []\r\n",
        "  for fold in folds:\r\n",
        "    # Calculate the average of val_loss of all epochs within current fold\r\n",
        "    fold_val_loss_avg = np.mean(fold['val_loss'])\r\n",
        "\r\n",
        "    folds_val_loss.append(fold_val_loss_avg)\r\n",
        "  \r\n",
        "  lr_val_loss.append(folds_val_loss)\r\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "eO7_3GoxqUkh",
        "outputId": "c0b2226b-b03c-4c85-d2cf-fd58eac9e561"
      },
      "source": [
        "i = 0\r\n",
        "for folds_val_loss in lr_val_loss:\r\n",
        "  plt.plot(np.arange(5),folds_val_loss, label='lr = '+str(lr_list[i]))\r\n",
        "  plt.ylabel('Validation loss')\r\n",
        "  plt.xlabel('Fold')\r\n",
        "  plt.legend()\r\n",
        "  plt.ylim([0, 1])\r\n",
        "  i += 1"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6gEbr_Y5P0x"
      },
      "source": [
        "**Conclusion:**\r\n",
        "\r\n",
        "From the above graph, we conlude that learning rate of 2e-5 gives the least validation loss, therefore the best performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBuw3vpk9NxJ"
      },
      "source": [
        "## Train with Optimal Hyperparameter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLoobXDF9pNx"
      },
      "source": [
        "We choose the optimal learning rate 2e-5 we got from previous step, train for 10 epochs with the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRCQL1gHq9jU"
      },
      "source": [
        "# Define some constants\r\n",
        "lr = 2e-5\r\n",
        "\r\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\r\n",
        "EPOCHS = 5\r\n",
        "BATCH_SIZE = 32\r\n",
        "DROPOUT = 0.3\r\n",
        "MAX_LEN = 32\r\n",
        "TOKENIZER = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w-mIPpT93Iz",
        "outputId": "d95a305f-96e6-48b5-9ed0-50d9e19cadfb"
      },
      "source": [
        "# Cross Validation\r\n",
        "kf = KFold(n_splits=5, shuffle=True)\r\n",
        "\r\n",
        "\r\n",
        "# Create model instance\r\n",
        "model = FinetuneBertClassifier(2)\r\n",
        "model = model.to(device)\r\n",
        "\r\n",
        "# Define optimizer, loss fucntion and scheduler\r\n",
        "optimizer = AdamW(model.parameters(), lr=lr, correct_bias=False)\r\n",
        "total_steps = len(train_data_loader) * EPOCHS\r\n",
        "scheduler = get_linear_schedule_with_warmup(\r\n",
        "  optimizer,\r\n",
        "  num_warmup_steps=0,\r\n",
        "  num_training_steps=total_steps\r\n",
        ")\r\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\r\n",
        "\r\n",
        "\r\n",
        "fold_history_list = []\r\n",
        "fold_count = 1\r\n",
        "# For each choice of lr, perform 5-fold cross validation\r\n",
        "for train_index, val_index in kf.split(train):\r\n",
        "  # Within each fold\r\n",
        "  print('Fold: ', fold_count)\r\n",
        "  print('-' * 10)\r\n",
        "  fold_count += 1\r\n",
        "\r\n",
        "  # Split the training data into train and validation set\r\n",
        "  train_data = train.iloc[train_index] \r\n",
        "  val_data = train.iloc[val_index] \r\n",
        "\r\n",
        "  # Count the number of training and validation set\r\n",
        "  num_train_data = len(train_data)\r\n",
        "  num_val_data = len(val_data)\r\n",
        "\r\n",
        "  # Create dataloaders for training and validation set\r\n",
        "  train_data_loader = create_data_loader(train_data, TOKENIZER, MAX_LEN, BATCH_SIZE)\r\n",
        "  val_data_loader = create_data_loader(val_data, TOKENIZER, MAX_LEN, BATCH_SIZE)\r\n",
        "\r\n",
        "\r\n",
        "  # Train the model for some number of epochs\r\n",
        "  history = defaultdict(list)\r\n",
        "\r\n",
        "  for epoch in range(EPOCHS):\r\n",
        "    print(f'Epoch {epoch + 1}/{EPOCHS}')\r\n",
        "    print('-' * 10)\r\n",
        "\r\n",
        "    # Train\r\n",
        "    train_acc, train_loss = train_epoch(\r\n",
        "      model,\r\n",
        "      train_data_loader,\r\n",
        "      loss_fn,\r\n",
        "      optimizer,\r\n",
        "      device,\r\n",
        "      scheduler,\r\n",
        "      len(train_data)\r\n",
        "    )\r\n",
        "    print(f'Train loss {train_loss} accuracy {train_acc}')\r\n",
        "\r\n",
        "    # Validate\r\n",
        "    val_acc, val_loss = eval_model(\r\n",
        "      model,\r\n",
        "      val_data_loader,\r\n",
        "      loss_fn,\r\n",
        "      device,\r\n",
        "      len(val_data)\r\n",
        "    )\r\n",
        "    print(f'Val   loss {val_loss} accuracy {val_acc}')\r\n",
        "  \r\n",
        "    history['train_acc'].append(train_acc)\r\n",
        "    history['train_loss'].append(train_loss)\r\n",
        "    history['val_acc'].append(val_acc)\r\n",
        "    history['val_loss'].append(val_loss)\r\n",
        "\r\n",
        "  # When we finish all epochs of current fold, \r\n",
        "  # history will be of size (4, EPOCHS)\r\n",
        "\r\n",
        "\r\n",
        "  # Then we append all epoch histories in current fold\r\n",
        "  # into fold_history_list\r\n",
        "  fold_history_list.append(history)\r\n",
        "\r\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold:  1\n",
            "----------\n",
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.49785079034679225 accuracy 0.774384236453202\n",
            "Val   loss 0.40758809447288513 accuracy 0.8135259356533158\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.33902962538974446 accuracy 0.864696223316913\n",
            "Val   loss 0.4382954682999601 accuracy 0.8141825344714378\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.23120109604413167 accuracy 0.912807881773399\n",
            "Val   loss 0.5261786555250486 accuracy 0.8207485226526592\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.15206795508293094 accuracy 0.9446633825944171\n",
            "Val   loss 0.6875047297216952 accuracy 0.8030203545633617\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.10125551634944771 accuracy 0.9637110016420362\n",
            "Val   loss 0.7195942912561198 accuracy 0.8194353250164149\n",
            "Fold:  2\n",
            "----------\n",
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.23821454119401697 accuracy 0.9333333333333333\n",
            "Val   loss 0.06327119421621319 accuracy 0.9737360472751149\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.23761937461448443 accuracy 0.9336617405582923\n",
            "Val   loss 0.06327119421621319 accuracy 0.9737360472751149\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.2442796025015304 accuracy 0.9279146141215107\n",
            "Val   loss 0.06327119421621319 accuracy 0.9737360472751149\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.24087452791196645 accuracy 0.9308702791461413\n",
            "Val   loss 0.06327119421621319 accuracy 0.9737360472751149\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.24815303902248412 accuracy 0.932512315270936\n",
            "Val   loss 0.06327119421621319 accuracy 0.9737360472751149\n",
            "Fold:  3\n",
            "----------\n",
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.24114784945067047 accuracy 0.9302134646962233\n",
            "Val   loss 0.0815010888230366 accuracy 0.9684832567301378\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.23686322434080023 accuracy 0.9292282430213465\n",
            "Val   loss 0.0815010888230366 accuracy 0.9684832567301378\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.24105780696693238 accuracy 0.9305418719211823\n",
            "Val   loss 0.0815010888230366 accuracy 0.9684832567301378\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.24440564311652552 accuracy 0.9298850574712644\n",
            "Val   loss 0.0815010888230366 accuracy 0.9684832567301378\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.24384359371054828 accuracy 0.9290640394088671\n",
            "Val   loss 0.0815010888230366 accuracy 0.9684832567301378\n",
            "Fold:  4\n",
            "----------\n",
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.24225001977707858 accuracy 0.9305532753242489\n",
            "Val   loss 0.054804382603227474 accuracy 0.9796320630749015\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.24753990442448184 accuracy 0.9290756854375307\n",
            "Val   loss 0.054804382603227474 accuracy 0.9796320630749015\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.2435011061357032 accuracy 0.928911508783451\n",
            "Val   loss 0.054804382603227474 accuracy 0.9796320630749015\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.24247927039420397 accuracy 0.9318666885568871\n",
            "Val   loss 0.054804382603227474 accuracy 0.9796320630749015\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.2538862878816929 accuracy 0.9272697422426531\n",
            "Val   loss 0.054804382603227474 accuracy 0.9796320630749015\n",
            "Fold:  5\n",
            "----------\n",
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.242482573703341 accuracy 0.932030865210967\n",
            "Val   loss 0.07170119932076584 accuracy 0.9717477003942182\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.24511014375925863 accuracy 0.9325233951732064\n",
            "Val   loss 0.07170119932076584 accuracy 0.9717477003942182\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.24334331156767622 accuracy 0.9313741585946478\n",
            "Val   loss 0.07170119932076584 accuracy 0.9717477003942182\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.24131792408648234 accuracy 0.9318666885568871\n",
            "Val   loss 0.07170119932076584 accuracy 0.9717477003942182\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.24187682117810913 accuracy 0.9318666885568871\n",
            "Val   loss 0.07170119932076584 accuracy 0.9717477003942182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkaI7LBCKPz8",
        "outputId": "79c5748a-0a19-4d3d-ca8a-26d33984aa05"
      },
      "source": [
        "val_acc_list = []\r\n",
        "for fold in fold_history_list:\r\n",
        "  acc_list = fold['val_acc']\r\n",
        "  for acc in acc_list:\r\n",
        "    acc = acc.item()\r\n",
        "    val_acc_list.append(acc)\r\n",
        "    \r\n",
        "print(val_acc_list)    "
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.8135259356533158, 0.8141825344714378, 0.8207485226526592, 0.8030203545633617, 0.8194353250164149, 0.9737360472751149, 0.9737360472751149, 0.9737360472751149, 0.9737360472751149, 0.9737360472751149, 0.9684832567301378, 0.9684832567301378, 0.9684832567301378, 0.9684832567301378, 0.9684832567301378, 0.9796320630749015, 0.9796320630749015, 0.9796320630749015, 0.9796320630749015, 0.9796320630749015, 0.9717477003942182, 0.9717477003942182, 0.9717477003942182, 0.9717477003942182, 0.9717477003942182]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "BTQbSu7P_q5V",
        "outputId": "68d83d8a-3c53-44a9-de93-b9315bbcafbb"
      },
      "source": [
        "plt.plot(val_acc_list)\r\n",
        "plt.ylabel('Validation Accuracy')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "\r\n",
        "print('Best validation accuracy: ', max(val_acc_list))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best validation accuracy:  0.9796320630749015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5cF0iOE_rir"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5xy2q2G_sqg"
      },
      "source": [
        "BATCH_SIZE = 32\r\n",
        "MAX_LEN = 32\r\n",
        "TOKENIZER = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMFsHrDZ_7FE"
      },
      "source": [
        "# Create test dataloader\r\n",
        "test_data_loader = create_data_loader(test, TOKENIZER, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_jmKoX8Bgyw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbodFb5cAFhg"
      },
      "source": [
        "# Make prediction on test set\r\n",
        "test_acc, _ = eval_model(\r\n",
        "  model,\r\n",
        "  test_data_loader,\r\n",
        "  loss_fn,\r\n",
        "  device,\r\n",
        "  len(test)\r\n",
        ")"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOmFvB31ASjs",
        "outputId": "3799cdf7-44f6-466d-9711-d660331adfb8"
      },
      "source": [
        "test_acc.item()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5902543671467974"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQMjrrm-R3Nh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}